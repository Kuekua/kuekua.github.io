<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      CS231n学习笔记--14. Reinforcement Learning | Kuekua&#39;s blog 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Kuekua Wu">
    
    

    <meta name="description" content="1. What is Reinforcement Learning概述：    举个栗子：    再举一个：    2. Markov Decision Process Mathematical formulation of the RL problem Markov property: Current state completely characterises the state of the">
<meta name="keywords" content="Algorithm,Machine Learning,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n学习笔记--14. Reinforcement Learning | Kuekua&#39;s blog">
<meta property="og:url" content="http://yoursite.com/2017/10/07/CS231n学习笔记--14. Reinforcement Learning/index.html">
<meta property="og:site_name" content="Kuekua&#39;s blog">
<meta property="og:description" content="1. What is Reinforcement Learning概述：    举个栗子：    再举一个：    2. Markov Decision Process Mathematical formulation of the RL problem Markov property: Current state completely characterises the state of the">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://img.blog.csdn.net/20171106213804400?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106213941094?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106214010744?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106214247108?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106214412283?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106214724725?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106214951418?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106220153278?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106220520502?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106220743538?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106221715449?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106221803301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106221935504?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106222820079?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223228947?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223426251?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223637933?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223812232?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223900710?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106223944772?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224050287?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224133084?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224258262?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224722426?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224839928?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106224946577?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106225036441?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106225124851?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106225229610?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:image" content="http://img.blog.csdn.net/20171106225424714?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
<meta property="og:updated_time" content="2017-11-06T15:16:06.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS231n学习笔记--14. Reinforcement Learning | Kuekua&#39;s blog">
<meta name="twitter:description" content="1. What is Reinforcement Learning概述：    举个栗子：    再举一个：    2. Markov Decision Process Mathematical formulation of the RL problem Markov property: Current state completely characterises the state of the">
<meta name="twitter:image" content="http://img.blog.csdn.net/20171106213804400?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.ico">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Kuekua&#39;s blog</a></h1>
        <hr class="panel-cover__divider" />

        
        <p class="panel-cover__description">
          YesterDay you said tomorrow!
        </p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">分类</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">CS231n学习笔记--14. Reinforcement Learning</h1>

    

    <div class="post-meta">
      <time datetime="2017-10-07" class="post-meta__date date">2017-10-07</time> 

      <span class="post-meta__tags tags">

          
            <font class="categories">
            &#8226; 分类:
            <a class="categories-link" href="/categories/CS231n/">CS231n</a>
            </font>
          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/Algorithm/">Algorithm</a>, <a class="tags-link" href="/tags/Deep-Learning/">Deep Learning</a>, <a class="tags-link" href="/tags/Machine-Learning/">Machine Learning</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h2 id="1-What-is-Reinforcement-Learning"><a href="#1-What-is-Reinforcement-Learning" class="headerlink" title="1. What is Reinforcement Learning"></a>1. What is Reinforcement Learning</h2><p>概述：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106213804400?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<p>举个栗子：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106213941094?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="60%"> <div align="left"></div></div></p>
<p>再举一个：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106214010744?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="60%"> <div align="left"></div></div></p>
<h2 id="2-Markov-Decision-Process"><a href="#2-Markov-Decision-Process" class="headerlink" title="2. Markov Decision Process"></a>2. Markov Decision Process</h2><ul>
<li>Mathematical formulation of the RL problem</li>
<li><strong>Markov property</strong>: Current state completely characterises the state of the world</li>
</ul>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106214247108?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><strong>处理流程：</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106214412283?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>The optimal policy π*</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106214724725?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<h2 id="3-Q-learning"><a href="#3-Q-learning" class="headerlink" title="3. Q-learning"></a>3. Q-learning</h2><p>Definitions: Value function and Q-value function：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106214951418?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<p>Bellman equation：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106220153278?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<p>优化策略：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106220520502?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106220743538?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><strong>Solving for the optimal policy: Q-learning</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106221715449?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<p>举个栗子：Playing Atari Games</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106221803301?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><strong>Q-network Architecture</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106221935504?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><strong>Training the Q-network: Experience Replay</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106222820079?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>Deep Q-Learning with Experience Replay</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106223228947?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<h2 id="4-Policy-Gradients"><a href="#4-Policy-Gradients" class="headerlink" title="4. Policy Gradients"></a>4. Policy Gradients</h2><p><div align="center"> <img src="http://img.blog.csdn.net/20171106223426251?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106223637933?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106223812232?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>Intuition：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106223900710?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>Variance reduction：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106223944772?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>Variance reduction: Baseline</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224050287?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>How to choose the baseline?</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224133084?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p>A better baseline: Want to push up the probability of an action from a state, if this action was better than the <strong>expected value of what we should get from that state</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224258262?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224722426?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><strong>Actor-Critic Algorithm</strong></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224839928?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106224946577?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="40%"> <div align="left"></div></div></p>
<h2 id="5-REINFORCE-的运用"><a href="#5-REINFORCE-的运用" class="headerlink" title="5. REINFORCE 的运用"></a>5. REINFORCE 的运用</h2><h3 id="5-1-Recurrent-Attention-Model-RAM"><a href="#5-1-Recurrent-Attention-Model-RAM" class="headerlink" title="5.1 Recurrent Attention Model (RAM)"></a>5.1 Recurrent Attention Model (RAM)</h3><p><div align="center"> <img src="http://img.blog.csdn.net/20171106225036441?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="80%"> <div align="left"></div></div></p>
<p>效果示意图：</p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106225124851?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<p><div align="center"> <img src="http://img.blog.csdn.net/20171106225229610?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<h3 id="5-2-AlphaGo"><a href="#5-2-AlphaGo" class="headerlink" title="5.2 AlphaGo"></a>5.2 AlphaGo</h3><p><div align="center"> <img src="http://img.blog.csdn.net/20171106225424714?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjU1NDA5Mg==/font/5a6L5L2T/fontsize/22/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="70%"> <div align="left"></div></div></p>
<h2 id="6-Summary"><a href="#6-Summary" class="headerlink" title="6. Summary"></a>6. Summary</h2><ul>
<li><strong>Policy gradients:</strong> very general but suffer from high variance so requires a lot of samples.<br><strong>Challenge:</strong> sample-efficiency</li>
<li><strong>Q-learning:</strong> does not always work but when it works, usually more sample-efficient. <strong>Challenge:</strong> exploration</li>
<li><strong>Guarantees:</strong><br> <strong>Policy Gradients:</strong> Converges to a local minima of J(θ),      often good enough!<br> <strong>Q-learning:</strong> Zero guarantees since you are approximating      Bellman equation with a complicated function approximator</li>
</ul>

  </section>

  <section class="post-comments">


<section id="comment">
<!-- UY BEGIN -->
<div id="uyan_frame"></div>
<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2147613"></script>
<!-- UY END -->
</section>

    
</section>


</article>


            <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Kuekua Wu</span>

  
</div>









<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共83.5k字</span>
</div>

        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    

    
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$$','$$'], ["\\(","\\)"] ],
      displayMath: [ ['$','$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
			    extensions: ["tex2jax.js"],
                jax: ["input/TeX", "output/HTML-CSS"],
                tex2jax: {inlineMath: [['[latex]','[/latex]'],['\\(','\\)']],
				          displayMath: [ ['$','$'], ["\\[","\\]"] ],
						  processEscapes: true
						  },
                "HTML-CSS": { availableFonts: ["TeX"] }						  
            });
        });
    </script>
	


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
				autoDetectHeadings: true,
				enableToTopButton: true,
				displayNow: true,
				title: "文章目录",
				css: {
					fontSize: "16px",
					largeFontSize: "20px",
					},
            });
        });
    </script>


    
    

    <script src="/js/jquery.githubRepoWidget.min.js"></script>


    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
